{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71edb016",
   "metadata": {},
   "source": [
    "## Demo: Stage1 processing for mooring data\n",
    "\n",
    "Read the original raw files and convert to netCDF. None to minimal additional processing.\n",
    "\n",
    "This notebook demonstrates the usage of the refactored `oceanarray.stage1_mooring` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "# Import the refactored stage1 processing module\n",
    "from oceanarray.stage1 import MooringProcessor, process_multiple_moorings, stage1_mooring\n",
    "\n",
    "# For testing individual readers (optional)\n",
    "from ctd_tools.readers import NortekAsciiReader, AdcpMatlabReader\n",
    "from ctd_tools.plotters import TimeSeriesPlotter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_section",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the base directory and mooring lists for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37139297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory containing the mooring data\n",
    "basedir = '/Users/eddifying/Dropbox/data/ifmro_mixsed/ds_data_eleanor/'\n",
    "\n",
    "# Define mooring lists\n",
    "all_moorings = ['ds2_X_2012', 'ds2_X_2017', 'ds2_X_2018',\n",
    "                'ds8_1_2012', 'ds9_1_2012', 'ds10_1_2012', 'ds11_1_2012', 'ds12_1_2012',\n",
    "                'ds13_1_2012', 'ds14_1_2012', 'ds15_1_2012', 'ds16_1_2012', 'ds17_1_2012',\n",
    "                'ds19_1_2012', 'ds18_1_2012', 'ds28_1_2017',\n",
    "                'dsA_1_2018', 'dsB_1_2018', 'dsC_1_2018', 'dsD_1_2018', 'dsE_1_2018', 'dsF_1_2018',\n",
    "                'dsM1_1_2017', 'dsM2_1_2017', 'dsM3_1_2017', 'dsM4_1_2017', 'dsM5_1_2017']\n",
    "\n",
    "# Subset for testing\n",
    "test_moorings_2018 = ['dsA_1_2018', 'dsB_1_2018', 'dsC_1_2018', 'dsD_1_2018', 'dsE_1_2018', 'dsF_1_2018']\n",
    "single_test = ['dsB_1_2018']\n",
    "\n",
    "# Choose which set to process\n",
    "moorlist = single_test\n",
    "\n",
    "print(f\"Base directory: {basedir}\")\n",
    "print(f\"Processing {len(moorlist)} moorings: {moorlist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processing_section",
   "metadata": {},
   "source": [
    "## Processing Moorings\n",
    "\n",
    "### Option 1: Using the new class-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e4a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processor\n",
    "processor = MooringProcessor(basedir)\n",
    "\n",
    "# Process each mooring individually with detailed output\n",
    "results = {}\n",
    "for mooring_name in moorlist:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing mooring: {mooring_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    success = processor.process_mooring(mooring_name)\n",
    "    results[mooring_name] = success\n",
    "\n",
    "    status = \"✅ SUCCESS\" if success else \"❌ FAILED\"\n",
    "    print(f\"\\nResult for {mooring_name}: {status}\")\n",
    "\n",
    "# Print final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL PROCESSING SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "successful = sum(results.values())\n",
    "total = len(results)\n",
    "print(f\"Successfully processed: {successful}/{total} moorings\")\n",
    "\n",
    "for mooring, success in results.items():\n",
    "    status = \"✅\" if success else \"❌\"\n",
    "    print(f\"{status} {mooring}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_processing",
   "metadata": {},
   "source": [
    "### Option 2: Using the convenience function for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use the batch processing function\n",
    "# Uncomment to use this approach instead\n",
    "\n",
    "if 0<0:\n",
    "    results = process_multiple_moorings(moorlist, basedir)\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"BATCH PROCESSING RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    for mooring, success in results.items():\n",
    "        status = \"SUCCESS\" if success else \"FAILED\"\n",
    "        print(f\"{mooring}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backwards_compat",
   "metadata": {},
   "source": [
    "### Option 3: Using the backwards-compatible function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compat_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use the original function signature for backwards compatibility\n",
    "# Uncomment to use this approach instead\n",
    "\n",
    "if 0:\n",
    "    for mooring_name in moorlist:\n",
    "        print(f\"Processing {mooring_name}...\")\n",
    "        success = stage1_mooring(mooring_name, basedir=basedir)\n",
    "        status = \"SUCCESS\" if success else \"FAILED\"\n",
    "        print(f\"{mooring_name}: {status}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing_section",
   "metadata": {},
   "source": [
    "## Testing Individual Readers\n",
    "\n",
    "Test reading specific instrument files directly to debug issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81775c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reading a Nortek AquaDopp file directly\n",
    "try:\n",
    "    rawdir = Path(basedir) / 'moor/raw/msm76_2018/'\n",
    "    instrument = 'aquadopp'\n",
    "    data_dir = rawdir / instrument\n",
    "    fname = 'DSC18_477102.dat'\n",
    "    filename = data_dir / fname\n",
    "    header_file = data_dir / (fname[:-4] + '.hdr')\n",
    "\n",
    "    print(f\"Data file: {filename}\")\n",
    "    print(f\"Header file: {header_file}\")\n",
    "    print(f\"Files exist: data={filename.exists()}, header={header_file.exists()}\")\n",
    "\n",
    "    if filename.exists() and header_file.exists():\n",
    "        reader = NortekAsciiReader(str(filename), header_file_path=str(header_file))\n",
    "        dataset = reader.get_data()\n",
    "\n",
    "        print(f\"\\nDataset loaded successfully!\")\n",
    "        print(f\"Variables: {list(dataset.data_vars)}\")\n",
    "        print(f\"Time range: {dataset.time.min().values} to {dataset.time.max().values}\")\n",
    "\n",
    "        # Plot if east_velocity exists\n",
    "        if 'east_velocity' in dataset.data_vars:\n",
    "            plotter = TimeSeriesPlotter(dataset)\n",
    "            plotter.plot(parameter_name='east_velocity')\n",
    "            plt.title(f'East Velocity - {fname}')\n",
    "            plt.show()\n",
    "\n",
    "        # Display dataset info\n",
    "        display(dataset)\n",
    "    else:\n",
    "        print(\"Files not found - skipping test\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error testing Nortek reader: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09961d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reading an ADCP MATLAB file directly\n",
    "try:\n",
    "    rawdir = Path(basedir) / 'moor/raw/msm76_2018/'\n",
    "    instrument = 'adcp'\n",
    "    data_dir = rawdir / instrument\n",
    "    fname = 'DS0218_RDI_000_24289.mat'\n",
    "    filename = data_dir / fname\n",
    "\n",
    "    print(f\"ADCP file: {filename}\")\n",
    "    print(f\"File exists: {filename.exists()}\")\n",
    "\n",
    "    if filename.exists():\n",
    "        reader = AdcpMatlabReader(str(filename))\n",
    "        dataset = reader.get_data()\n",
    "\n",
    "        print(f\"\\nADCP Dataset loaded successfully!\")\n",
    "        print(f\"Variables: {list(dataset.data_vars)}\")\n",
    "        print(f\"Time range: {dataset.time.min().values} to {dataset.time.max().values}\")\n",
    "\n",
    "        # Plot pressure if it exists\n",
    "        if 'pressure' in dataset.data_vars:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.plot(dataset.time, dataset.pressure)\n",
    "            plt.title(f'Pressure - {fname}')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Pressure')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        # Display dataset info\n",
    "        display(dataset)\n",
    "    else:\n",
    "        print(\"File not found - skipping test\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error testing ADCP reader: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis_section",
   "metadata": {},
   "source": [
    "## Analyzing Processed Results\n",
    "\n",
    "Load and visualize the processed NetCDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b34a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze processed files\n",
    "def analyze_processed_mooring(mooring_name, basedir, instrument_type='microcat'):\n",
    "    \"\"\"Analyze processed files for a specific mooring and instrument type.\"\"\"\n",
    "    proc_dir = Path(basedir) / 'moor/proc' / mooring_name / instrument_type\n",
    "    fig_dir = proc_dir\n",
    "\n",
    "    if not proc_dir.exists():\n",
    "        print(f\"Directory not found: {proc_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Analyzing processed files in: {proc_dir}\")\n",
    "\n",
    "    # Find all NetCDF files\n",
    "    nc_files = list(proc_dir.glob('*raw.nc'))\n",
    "    if not nc_files:\n",
    "        print(\"No NetCDF files found\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(nc_files)} NetCDF files:\")\n",
    "\n",
    "    for file_path in nc_files:\n",
    "        try:\n",
    "            print(f\"\\n📄 Loading: {file_path.name}\")\n",
    "\n",
    "            with xr.open_dataset(file_path) as dataset:\n",
    "                print(f\"   Variables: {list(dataset.data_vars)}\")\n",
    "                print(f\"   Attributes: {list(dataset.attrs.keys())}\")\n",
    "\n",
    "                # Extract key metadata\n",
    "                mooring_name_attr = dataset.attrs.get('mooring_name', 'Unknown')\n",
    "                instrument_name = dataset.get('instrument', 'Unknown').values if 'instrument' in dataset else 'Unknown'\n",
    "                serial_number = dataset.get('serial_number', 0).values if 'serial_number' in dataset else 0\n",
    "\n",
    "                print(f\"   Mooring: {mooring_name_attr}\")\n",
    "                print(f\"   Instrument: {instrument_name}\")\n",
    "                print(f\"   Serial: {serial_number}\")\n",
    "\n",
    "                # Plot temperature if available\n",
    "                if 'temperature' in dataset.data_vars:\n",
    "                    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "                    ax.plot(dataset['time'], dataset['temperature'], 'b-', linewidth=0.5)\n",
    "                    ax.set_ylabel('Temperature (°C)')\n",
    "                    ax.set_title(f'{mooring_name_attr}: {instrument_name} {serial_number} - Temperature')\n",
    "                    ax.set_xlabel('Time')\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "\n",
    "                    # Add stats\n",
    "                    temp_mean = dataset['temperature'].mean().values\n",
    "                    temp_std = dataset['temperature'].std().values\n",
    "                    ax.text(0.02, 0.98, f'Mean: {temp_mean:.2f}°C\\nStd: {temp_std:.2f}°C',\n",
    "                           transform=ax.transAxes, verticalalignment='top',\n",
    "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                    # Save plot\n",
    "                    plot_name = f\"{mooring_name_attr}_{instrument_name}_{serial_number}_temperature_raw.png\"\n",
    "                    fig.savefig(fig_dir / plot_name, dpi=150, bbox_inches='tight')\n",
    "                    print(f\"   📊 Plot saved: {plot_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error loading {file_path.name}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "if results and any(results.values()):\n",
    "    # Analyze the first successfully processed mooring\n",
    "    successful_mooring = next(mooring for mooring, success in results.items() if success)\n",
    "    print(f\"\\nAnalyzing successful mooring: {successful_mooring}\")\n",
    "    analyze_processed_mooring(successful_mooring, basedir, 'microcat')\n",
    "else:\n",
    "    print(\"No successfully processed moorings to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ab628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
