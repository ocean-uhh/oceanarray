{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "streamlined-demo",
   "metadata": {},
   "source": "# Demo: Streamlined Clock Offset Analysis\n\n**Note: This is a refactored version by Claude. See `demo_check_clock.ipynb` for the original user file.**\n\nThis notebook provides a streamlined version of clock offset analysis for oceanographic instruments.\nIt uses the new `oceanarray.clock_offset` module for cleaner, more maintainable code.\n\n## Purpose\n\nThis notebook helps determine whether instrument timestamps are incorrect by:\n1. Analyzing deployment timing based on temperature profiles\n2. Performing lag correlation analysis between instruments\n3. Calculating recommended clock offset corrections\n\n**Note:** This notebook does not modify data files. It only analyzes and suggests clock_offset values for the YAML configuration."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from oceanarray import clock_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "mooring_name = 'dsE_1_2018'\n",
    "base_dir = '/Users/eddifying/Dropbox/data/ifmro_mixsed/ds_data_eleanor/'\n",
    "output_path = base_dir + 'moor/proc/'\n",
    "\n",
    "# Choose file type: '_raw' for original data, '_use' for processed data\n",
    "file_suffix = '_raw'\n",
    "# file_suffix = '_use'\n",
    "\n",
    "print(f\"Analyzing mooring: {mooring_name}\")\n",
    "print(f\"Using files with suffix: {file_suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load instrument data\n",
    "datasets, moor_yaml_data = clock_offset.load_mooring_instruments(\n",
    "    mooring_name, base_dir, output_path, file_suffix\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(datasets)} instruments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create common time grid and interpolate\n",
    "time_grid = clock_offset.create_common_time_grid(datasets)\n",
    "datasets_interp = clock_offset.interpolate_datasets_to_grid(datasets, time_grid)\n",
    "\n",
    "# Combine into single multi-level dataset\n",
    "combined_ds = clock_offset.combine_interpolated_datasets(datasets_interp)\n",
    "\n",
    "print(f\"Combined dataset shape: {combined_ds.dims}\")\n",
    "print(f\"Time grid length: {len(time_grid)}\")\n",
    "print(f\"Time range: {time_grid[0]} to {time_grid[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deployment-analysis",
   "metadata": {},
   "source": [
    "## Deployment Timing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze deployment timing using temperature profiles\n",
    "combined_ds = clock_offset.analyze_deployment_timing(combined_ds)\n",
    "\n",
    "print(\"Deployment timing analysis completed\")\n",
    "print(f\"Dataset now includes: {list(combined_ds.data_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## Visualize Temperature Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-profiles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature time series with deployment bounds\n",
    "time = combined_ds[\"time\"].values\n",
    "temp = combined_ds[\"temperature\"].values\n",
    "split_vals = combined_ds[\"split_value\"].values\n",
    "instruments = combined_ds[\"instrument\"].values\n",
    "start_times = combined_ds[\"start_time\"].values\n",
    "end_times = combined_ds[\"end_time\"].values\n",
    "\n",
    "for i in range(combined_ds.dims[\"N_LEVELS\"]):\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    ax.plot(time, temp[:, i], label=f\"{instruments[i]}\", alpha=0.7)\n",
    "    ax.axhline(split_vals[i], color=\"red\", linestyle=\"--\",\n",
    "               label=f\"Split={split_vals[i]:.2f}\")\n",
    "\n",
    "    # Plot deployment bounds if available\n",
    "    if np.isfinite(start_times[i].astype(\"datetime64[ns]\").astype(\"int64\")):\n",
    "        ax.axvline(start_times[i], color=\"green\", linestyle=\"--\", lw=2,\n",
    "                   label=\"Deployment Start\")\n",
    "    if np.isfinite(end_times[i].astype(\"datetime64[ns]\").astype(\"int64\")):\n",
    "        ax.axvline(end_times[i], color=\"blue\", linestyle=\"--\", lw=2,\n",
    "                   label=\"Deployment End\")\n",
    "\n",
    "    ax.set_title(f\"Instrument {i}: {instruments[i]} at {combined_ds['nominal_depth'][i].values:.0f}m\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Temperature (°C)\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timing-offsets",
   "metadata": {},
   "source": [
    "## Calculate Timing Offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j8sqaaoe1ki",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate timing offsets based on deployment bounds\n",
    "offset_results = clock_offset.calculate_timing_offsets(combined_ds)\n",
    "\n",
    "# Print summary table\n",
    "clock_offset.print_timing_offset_summary(combined_ds, offset_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9tcfvxw0pmr",
   "metadata": {},
   "source": [
    "## Detailed Deployment Boundary Visualization\n",
    "\n",
    "Examine the exact transition points with individual measurements around predicted deployment boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xihcsh8sa6q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed deployment boundaries showing individual measurements\n",
    "# This shows 10 samples before/after predicted boundaries with red circles and blue connecting lines\n",
    "clock_offset.plot_deployment_boundaries(datasets, combined_ds, n_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correlation-analysis",
   "metadata": {},
   "source": [
    "## Lag Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get suggestion for best reference instrument (but you can override manually)\n",
    "ref_suggestion = clock_offset.suggest_reference_instrument(combined_ds, offset_results)\n",
    "\n",
    "# Use the suggested reference (or manually set ref_index to any value you prefer)\n",
    "ref_index = ref_suggestion['suggested_index']  # You can change this manually\n",
    "sub_sample = 5  # Subsampling factor for speed\n",
    "\n",
    "print(f\"Using reference instrument: Index {ref_index}\")\n",
    "print(f\"Note: You can manually set ref_index to any instrument index (0-{combined_ds.sizes['N_LEVELS']-1})\")\n",
    "print()\n",
    "\n",
    "correlation_results = clock_offset.perform_lag_correlation_analysis(\n",
    "    combined_ds, ref_index=ref_index, sub_sample=sub_sample\n",
    ")\n",
    "\n",
    "# Print correlation summary\n",
    "clock_offset.print_correlation_summary(combined_ds, correlation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-correlations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation results\n",
    "time_interval = correlation_results['time_interval']\n",
    "sub_sample = correlation_results['sub_sample']\n",
    "depths = combined_ds['nominal_depth'].values\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "max_lag_sub = len(correlation_results['correlations'][0]) // 2\n",
    "lags_sub = np.arange(-max_lag_sub, max_lag_sub + 1)\n",
    "\n",
    "for i, corrs in enumerate(correlation_results['correlations']):\n",
    "    dt_sub = sub_sample * time_interval\n",
    "    plt.plot(lags_sub * dt_sub, corrs,\n",
    "             label=f'Level {i+1} ({depths[i]:.0f}m)', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Lag (seconds)')\n",
    "plt.ylabel('Correlation')\n",
    "plt.title(f'Lag Correlation Analysis (Reference: Level {ref_index+1})')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-plot",
   "metadata": {},
   "source": [
    "## Summary: All Temperature Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all temperature time series together\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i in range(combined_ds.sizes['N_LEVELS']):\n",
    "    depth = combined_ds['nominal_depth'][i].values\n",
    "    instrument = combined_ds['instrument'][i].values\n",
    "    serial = combined_ds['serial_number'][i].values\n",
    "\n",
    "    plt.plot(combined_ds['time'], combined_ds['temperature'][:, i],\n",
    "             label=f'{instrument} #{serial} ({depth:.0f}m)', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title(f'Temperature Time Series - {mooring_name}')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recommendations",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "Based on the analysis above:\n",
    "\n",
    "1. **Deployment Timing Analysis**: Shows offset estimates based on when instruments first/last detect \"deep\" water temperatures\n",
    "2. **Lag Correlation Analysis**: Shows offset estimates based on cross-correlation of temperature time series\n",
    "\n",
    "Use the **negative** of the calculated offset as the `clock_offset` value in the YAML file.\n",
    "\n",
    "After updating the YAML file, run stage2 processing to apply the corrections, then re-run this analysis with `file_suffix = '_use'` to verify the corrections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
