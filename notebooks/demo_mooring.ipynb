{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a29764-f39c-431c-8e77-fbc6bfe20f01",
   "metadata": {},
   "source": [
    "# Demo: mooring-level processing (Step 1)\n",
    "\n",
    "This notebook demonstrates the first of the mooring-level processing steps, time_gridding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006edeaa",
   "metadata": {},
   "source": [
    "## Step 1: Time Gridding and Optional Filtering Demo\n",
    "\n",
    "This notebook demonstrates the Step 1 processing workflow for mooring data:\n",
    "- Loading multiple instrument datasets\n",
    "- Optional time-domain filtering (applied BEFORE interpolation)\n",
    "- Interpolating onto a common time grid\n",
    "- Combining into a unified mooring dataset\n",
    "\n",
    "**Key Point**: Filtering is applied to individual instrument records on their native time grids BEFORE interpolation to preserve data integrity.\n",
    "\n",
    "Version: 1.0  \n",
    "Date: 2025-09-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1920f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Import the time gridding module\n",
    "from oceanarray.time_gridding import (\n",
    "    TimeGriddingProcessor,\n",
    "    time_gridding_mooring,\n",
    "    process_multiple_moorings_time_gridding\n",
    ")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6e0e5",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "### Configuration\n",
    "\n",
    "First, let's set up our data paths and examine the mooring configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce860d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your data paths here\n",
    "basedir = '../data'\n",
    "mooring_name = 'dsE_1_2018'\n",
    "\n",
    "# Construct paths\n",
    "proc_dir = Path(basedir) / 'moor' / 'proc' / mooring_name\n",
    "config_file = proc_dir / f\"{mooring_name}.mooring.yaml\"\n",
    "\n",
    "print(f\"Processing directory: {proc_dir}\")\n",
    "print(f\"Configuration file: {config_file}\")\n",
    "print(f\"Config exists: {config_file.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the mooring configuration\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    print(\"Mooring Configuration:\")\n",
    "    print(f\"Name: {config['name']}\")\n",
    "    print(f\"Water depth: {config.get('waterdepth', 'unknown')} m\")\n",
    "    print(f\"Location: {config.get('latitude', 'unknown')}°N, {config.get('longitude', 'unknown')}°E\")\n",
    "    print(f\"\\nInstruments ({len(config.get('instruments', []))}):\")\n",
    "\n",
    "    for i, inst in enumerate(config.get('instruments', [])):\n",
    "        print(f\"  {i+1}. {inst.get('instrument', 'unknown')} \"\n",
    "              f\"(serial: {inst.get('serial num.', 'unknown')}) at {inst.get('depth', 'unknown')} m\")\n",
    "else:\n",
    "    print(\"Configuration file not found!\")\n",
    "    print(\"Please check your data path and mooring name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87567a6",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "### Examine individual instrument files\n",
    "\n",
    "Let's look at the individual instrument files before processing to understand the different sampling rates and data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and examine individual instrument files\n",
    "file_suffix = \"_use\"\n",
    "instrument_files = []\n",
    "instrument_datasets = []\n",
    "rows = []\n",
    "\n",
    "if config_file.exists():\n",
    "    for inst_config in config.get(\"instruments\", []):\n",
    "        instrument_type = inst_config.get(\"instrument\", \"unknown\")\n",
    "        serial = inst_config.get(\"serial\", 0)\n",
    "        depth = inst_config.get(\"depth\", 0)\n",
    "\n",
    "        # Look for the file\n",
    "        filename = f\"{mooring_name}_{serial}{file_suffix}.nc\"\n",
    "        filepath = proc_dir / instrument_type / filename\n",
    "\n",
    "        if filepath.exists():\n",
    "            ds = xr.open_dataset(filepath)\n",
    "            instrument_files.append(filepath)\n",
    "            instrument_datasets.append(ds)\n",
    "\n",
    "            # Time coverage\n",
    "            t0, t1 = ds.time.values[0], ds.time.values[-1]\n",
    "            npoints = len(ds.time)\n",
    "\n",
    "            # Median sampling interval\n",
    "            time_diff = np.diff(ds.time.values) / np.timedelta64(1, \"m\")  # in minutes\n",
    "            median_interval = np.nanmedian(time_diff)\n",
    "            if median_interval > 1:\n",
    "                sampling = f\"{median_interval:.1f} min\"\n",
    "            else:\n",
    "                sampling = f\"{median_interval*60:.1f} sec\"\n",
    "\n",
    "            # Collect a row for the table\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"Instrument\": instrument_type,\n",
    "                    \"Serial\": serial,\n",
    "                    \"Depth [m]\": depth,\n",
    "                    \"File\": filepath.name,\n",
    "                    \"Start\": str(t0)[:19],\n",
    "                    \"End\": str(t1)[:19],\n",
    "                    \"Points\": npoints,\n",
    "                    \"Sampling\": sampling,\n",
    "                    \"Variables\": \", \".join(list(ds.data_vars)),\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"Instrument\": instrument_type,\n",
    "                    \"Serial\": serial,\n",
    "                    \"Depth [m]\": depth,\n",
    "                    \"File\": \"MISSING\",\n",
    "                    \"Start\": \"\",\n",
    "                    \"End\": \"\",\n",
    "                    \"Points\": 0,\n",
    "                    \"Sampling\": \"\",\n",
    "                    \"Variables\": \"\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Make a DataFrame summary\n",
    "    summary = pd.DataFrame(rows)\n",
    "    pd.set_option(\"display.max_colwidth\", 80)  # allow long var lists\n",
    "    print(summary.to_markdown(index=False))\n",
    "\n",
    "    print(f\"\\nFound {len(instrument_datasets)} instrument datasets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5ace6",
   "metadata": {},
   "source": [
    "### Process with time gridding (no filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process without filtering\n",
    "print(\"Processing mooring with time gridding only (no filtering)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = time_gridding_mooring(mooring_name, basedir, file_suffix='_use')\n",
    "\n",
    "print(f\"\\nProcessing result: {'SUCCESS' if result else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the combined dataset\n",
    "output_file = proc_dir / f\"{mooring_name}_mooring_use.nc\"\n",
    "\n",
    "if output_file.exists():\n",
    "    print(f\"Output file exists: {output_file}\")\n",
    "\n",
    "    # Load the combined dataset\n",
    "    combined_ds = xr.open_dataset(output_file)\n",
    "else:\n",
    "    print(\"Output file not found - processing may have failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26f061",
   "metadata": {},
   "source": [
    "### Visualize Combined Dataset\n",
    "\n",
    "Let's plot the combined dataset to see how the different instruments look on the common time grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68780c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_combined_timeseries(\n",
    "    combined_ds,\n",
    "    variables=(\"temperature\", \"salinity\", \"pressure\"),\n",
    "    cmap_name=\"viridis\",\n",
    "    line_alpha=0.8,\n",
    "    line_width=1.2,\n",
    "    percentile_limits=(1, 99),\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot selected variables from a combined mooring dataset as stacked time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    combined_ds : xarray.Dataset\n",
    "        Must have dims: time, N_LEVELS. Optional coords: nominal_depth, serial_number.\n",
    "    variables : iterable[str]\n",
    "        Variable names to try to plot (if present in dataset).\n",
    "    cmap_name : str\n",
    "        Matplotlib colormap name for coloring by instrument level.\n",
    "    line_alpha : float\n",
    "        Line transparency.\n",
    "    line_width : float\n",
    "        Line width.\n",
    "    percentile_limits : (low, high)\n",
    "        Percentiles to use for automatic y-limits (e.g., (1, 99)).\n",
    "    \"\"\"\n",
    "    if combined_ds is None:\n",
    "        print(\"Combined dataset not available.\")\n",
    "        return None, None\n",
    "    n_levels = combined_ds.sizes.get(\"N_LEVELS\")\n",
    "    if n_levels is None:\n",
    "        raise ValueError(\"Dataset must contain dimension 'N_LEVELS'.\")\n",
    "\n",
    "    available = [v for v in variables if v in combined_ds.data_vars]\n",
    "    if not available:\n",
    "        print(\"No requested variables found to plot.\")\n",
    "        return None, None\n",
    "\n",
    "    # Colors by level\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    colors = cmap(np.linspace(0, 1, n_levels))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        len(available), 1, figsize=(14, 3.6 * len(available)), sharex=True, constrained_layout=True\n",
    "    )\n",
    "    if len(available) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    depth_arr = combined_ds.get(\"nominal_depth\")\n",
    "    serial_arr = combined_ds.get(\"serial_number\")\n",
    "\n",
    "    first_axis = True\n",
    "    for ax, var in zip(axes, available):\n",
    "        values_for_limits = []\n",
    "        for level in range(n_levels):\n",
    "            depth = None if depth_arr is None else depth_arr.values[level]\n",
    "            serial = None if serial_arr is None else serial_arr.values[level]\n",
    "            label = None\n",
    "            if first_axis:\n",
    "                if depth is not None and np.isfinite(depth):\n",
    "                    label = f\"Serial {serial} ({int(depth)} m)\" if serial is not None else f\"({int(depth)} m)\"\n",
    "                elif serial is not None:\n",
    "                    label = f\"Serial {serial}\"\n",
    "\n",
    "            da = combined_ds[var].isel(N_LEVELS=level)\n",
    "            da = da.where(np.isfinite(da), drop=True)\n",
    "            if da.size == 0:\n",
    "                continue\n",
    "\n",
    "            values_for_limits.append(da.values)\n",
    "\n",
    "            ax.plot(\n",
    "                da[\"time\"].values,\n",
    "                da.values,\n",
    "                color=colors[level],\n",
    "                alpha=line_alpha,\n",
    "                linewidth=line_width,\n",
    "                label=label,\n",
    "            )\n",
    "\n",
    "        # Set labels and grid\n",
    "        ax.set_ylabel(var.replace(\"_\", \" \").title())\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_title(f\"{var.replace('_', ' ').title()} — Combined Time Grid\")\n",
    "\n",
    "        # Legend only once\n",
    "        if first_axis:\n",
    "            ax.legend(ncol=3, fontsize=8, loc=\"upper right\", frameon=False)\n",
    "            first_axis = False\n",
    "\n",
    "        # Auto y-limits based on percentiles\n",
    "        if values_for_limits:\n",
    "            flat = np.concatenate(values_for_limits)\n",
    "            low, high = np.nanpercentile(flat, percentile_limits)\n",
    "            ax.set_ylim(low, high)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Time\")\n",
    "    return fig, axes\n",
    "\n",
    "# Usage:\n",
    "if 'combined_ds' in locals():\n",
    "    plot_combined_timeseries(combined_ds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
